{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### import"
      ],
      "metadata": {
        "id": "c2eH8OLVhSq0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAUkG8sIjPIs"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "import zipfile\n",
        "import gdown\n",
        "import albumentations as A\n",
        "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 마운트 시도 (실패)\n",
        "\n",
        "\n",
        "> memo Gdown으로 했더니 에러가 나는 거 같고, 마운트를 하면 내 드라이브에서 하라고 하고, 공유에서는 안 된다고 하고.. 무슨 API 서비스 사용하라고 하는데 그거는 하기까지 시간이 오래 걸릴 거 같고...\n",
        "\n"
      ],
      "metadata": {
        "id": "dqGp3a6zmAES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drive.mount('/content/drive')\n",
        "\n",
        "# drive_folder = \"/content/drive/MyDrive/original_image/original_image\"\n",
        "# zip_filename = \"bread.zip\"\n",
        "\n",
        "# os.chdir(\"/content\")\n",
        "\n",
        "# with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "#     for root, dirs, files in os.walk(drive_folder):\n",
        "#         for file in files:\n",
        "#             file_path = os.path.join(root, file)\n",
        "#             zipf.write(file_path, os.path.relpath(file_path, drive_folder))\n",
        "\n",
        "# files.download(zip_filename)\n",
        "\n",
        "# print(f\"데이터셋 다운 / 압해 완료\")\n",
        "\n",
        "# # https://drive.google.com/drive/folders/1TEHUAt9HuD3rH5iqrdJQAB70cmOXcn_9?usp=sharing"
      ],
      "metadata": {
        "id": "JO1uocPGjWO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정석님이 올려두신 labeling data + image set (새로운 라벨링 위해서 주석 처리)"
      ],
      "metadata": {
        "id": "WLNiHJns6FRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 정석님이 올려두신 roboflow labeling data 가져오기\n",
        "\n",
        "# # dataset_path = \"/content/bread/original_image\" # 원본 이미지 경로\n",
        "\n",
        "# label_zip_file_id = \"10VZf9IqZ0bVHFCIcELrWmLS01Kh0pzF-\"\n",
        "# labeling_output_name = \"image_label_data.zip\"\n",
        "# # https://drive.google.com/file/d/10VZf9IqZ0bVHFCIcELrWmLS01Kh0pzF-/view?usp=drive_link\n",
        "\n",
        "# # 기존 파일 있으면 삭제\n",
        "# if os.path.exists(labeling_output_name):\n",
        "#     os.remove(labeling_output_name)\n",
        "#     print(f\"기존 파일 삭제\")\n",
        "\n",
        "# gdown.download(f\"https://drive.google.com/uc?id={label_zip_file_id}\", labeling_output_name, quiet=False)\n",
        "# print(f\"labeling zip 다운\")\n",
        "\n",
        "# # 압축해제 절대경로 설정 했지만 안되는 거 같아서 그냥 두기로\n",
        "# labels_path = \"/content/bread/\"\n",
        "\n",
        "# # 기존 폴더 있으면 삭제\n",
        "# if os.path.exists(labels_path):\n",
        "#     shutil.rmtree(labels_path)\n",
        "#     print(f\"기존 폴더 삭제\")\n",
        "\n",
        "# os.makedirs(labels_path, exist_ok=True)\n",
        "\n",
        "# # 압해\n",
        "# label_zip_file_path = os.path.join(os.getcwd(), labeling_output_name)\n",
        "\n",
        "# with zipfile.ZipFile(label_zip_file_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(labels_path)\n",
        "\n",
        "# print(f\"압축 해제 데이터 경로: {labels_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOZGeDafsuBx",
        "outputId": "47ec9e97-28aa-41a8-af93-966f5948cfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=10VZf9IqZ0bVHFCIcELrWmLS01Kh0pzF-\n",
            "From (redirected): https://drive.google.com/uc?id=10VZf9IqZ0bVHFCIcELrWmLS01Kh0pzF-&confirm=t&uuid=1ba515fe-b0fa-4b66-83d4-e6eeb56a8f90\n",
            "To: /content/image_label_data.zip\n",
            "100%|██████████| 53.4M/53.4M [00:02<00:00, 23.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeling zip 다운\n",
            "압축 해제 데이터 경로: /content/bread/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⚠️윤곽선 포함 사진으로 라벨링 -> 훈련 과정 새로 시작\n",
        "\n",
        "\n",
        "> 정석님이 올려주신 labeling 데이터를 사용하려고 했으나, 증강 이미지가 포함된 걸로 다시 라벨링이 필요하다는 것을 알게 됐음. edge/contours_detection 적용한 사진 파일을 저장하고, 빵 폴더별로 구분해서 포함시켜놓은 다음에, 다시 라벨링하고, gdown하고, 훈련 돌리면 된다.\n",
        "\n"
      ],
      "metadata": {
        "id": "2OoZwERc1DHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gdown(이전 버전)(주석처리)"
      ],
      "metadata": {
        "id": "o0oCpxyri5s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# zip_file_id = \"1kSApTuj4bC3vtHJ-0t2HTkPaay7CTt0H\"\n",
        "# output_name = \"bread_data.zip\"\n",
        "\n",
        "# # 기존 파일 있으면 삭제\n",
        "# if os.path.exists(output_name):\n",
        "#     os.remove(output_name)\n",
        "#     print(f\"기존 파일 삭제\")\n",
        "\n",
        "# gdown.download(f\"https://drive.google.com/uc?id={zip_file_id}\", output_name, quiet=False)\n",
        "# print(f\"zip 다운\")\n",
        "\n",
        "# # 압축해제 절대경로 설정 했지만 안되는 거 같아서 그냥 두기로\n",
        "# extract_path = r\"bread\"\n",
        "\n",
        "# # 기존 폴더 있으면 삭제\n",
        "# if os.path.exists(extract_path):\n",
        "#     shutil.rmtree(extract_path)\n",
        "#     print(f\"기존 폴더 삭제\")\n",
        "\n",
        "# os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# # 압해\n",
        "# zip_file_path = os.path.join(os.getcwd(), output_name)\n",
        "\n",
        "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_path)\n",
        "\n",
        "# print(f\"압축 해제 데이터 경로: {extract_path}\")"
      ],
      "metadata": {
        "id": "0qko9xOk1G5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 윤곽선/경계선 : Edge 및 Contour Detection 함수"
      ],
      "metadata": {
        "id": "v96WyWqhQcB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def detect_edges_and_contours(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"이미지를 읽을 수 없어요: {image_path}\")\n",
        "        return None, None\n",
        "\n",
        "    # 그레이스케일 변환 (경계선 강화!)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Canny Edge Detection\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "    # Contour Detection\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contour_image = image.copy()\n",
        "    cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
        "\n",
        "    return edges, contour_image\n",
        "\n",
        "dataset_path = \"/content/bread/train/images/\"\n",
        "output_path = \"/content/bread/edge/\"\n",
        "\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "for image_file in os.listdir(dataset_path):\n",
        "    if image_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "        image_path = os.path.join(dataset_path, image_file)\n",
        "\n",
        "        # 경계선 및 윤곽선 추출\n",
        "        edges, contour_image = detect_edges_and_contours(image_path)\n",
        "        if edges is not None:\n",
        "\n",
        "            edge_output = os.path.join(output_path, f\"{os.path.splitext(image_file)[0]}_edges.jpg\")\n",
        "            contour_output = os.path.join(output_path, f\"{os.path.splitext(image_file)[0]}_contours.jpg\")\n",
        "\n",
        "            cv2.imwrite(edge_output, edges)  # 경계선 이미지 저장\n",
        "            cv2.imwrite(contour_output, contour_image)  # 윤곽선 이미지 저장\n",
        "\n",
        "print(f\"결과 저장 완료: {output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NLPgM71yQbpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd17d29-fbca-41a8-e53c-5223c8780913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결과 저장 완료: /content/bread/edge/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shutil.make_archive(\"/content/bread/edge\", 'zip', \"/content/bread/edge\")\n",
        "\n",
        "# files.download(\"/content/bread/edge.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MMLALxhBoDAd",
        "outputId": "06e369ed-b6f7-49db-b4c2-a1bfcb59d006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2dbeb931-8617-4f9d-836d-82d7b3c7b404\", \"edge.zip\", 156427199)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 베이글로 테스트"
      ],
      "metadata": {
        "id": "Ip0yG93qQkqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bread = \"bagel\" # 샘플\n",
        "# output_path = os.path.join(dataset_path, bread, \"edge_contours\")\n",
        "# if os.path.exists(output_path):\n",
        "#     edge_files = sorted([f for f in os.listdir(output_path) if \"edges\" in f])[:4]\n",
        "\n",
        "#     plt.figure(figsize=(10, 5))\n",
        "#     for i, edge_file in enumerate(edge_files):\n",
        "#         edge_image = cv2.imread(os.path.join(output_path, edge_file), cv2.IMREAD_GRAYSCALE)\n",
        "#         plt.subplot(1, 4, i + 1)\n",
        "#         plt.imshow(edge_image, cmap='gray')\n",
        "#         plt.title(edge_file)\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "# else:\n",
        "#     print(\"_\")"
      ],
      "metadata": {
        "id": "kDvYtX7tQjtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distance Transform 활용 (임시 중단)"
      ],
      "metadata": {
        "id": "b95kH8J2zd_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def apply_distance_transform(image_path):\n",
        "#     image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "#     if image is None:\n",
        "#         return None\n",
        "\n",
        "#     _, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "#     dist_transform = cv2.distanceTransform(binary, cv2.DIST_L2, 3)\n",
        "#     return dist_transform\n",
        "\n",
        "# dataset_path = \"/content/bread/original_image\"\n",
        "\n",
        "# for bread in os.listdir(dataset_path):\n",
        "#     bread_images_path = os.path.join(dataset_path, bread, \"images\")\n",
        "#     if os.path.exists(bread_images_path):\n",
        "#         print(f\"{bread}...\")\n",
        "\n",
        "#         output_path = os.path.join(dataset_path, bread, \"distance_transform\")\n",
        "#         os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "#         for image_file in os.listdir(bread_images_path):\n",
        "#             if image_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "#                 image_path = os.path.join(bread_images_path, image_file)\n",
        "\n",
        "#                 distance_image = apply_distance_transform(image_path)\n",
        "#                 if distance_image is not None:\n",
        "#                     output_file = os.path.join(output_path, f\"{os.path.splitext(image_file)[0]}_dist.jpg\")\n",
        "#                     cv2.imwrite(output_file, (distance_image * 255).astype(\"uint8\"))  # 0~255로 스케일 조정\n",
        "\n",
        "#         print(f\"{bread}:{output_path} 저장\")\n",
        "#     else:\n",
        "#         print(f\"{bread}: 이미지 없음\")\n"
      ],
      "metadata": {
        "id": "kmC_w-9kzfn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bread = \"bagel\"\n",
        "# output_path = os.path.join(dataset_path, bread, \"distance_transform\")\n",
        "\n",
        "# if os.path.exists(output_path):\n",
        "#     dist_files = sorted(os.listdir(output_path))[:4]\n",
        "\n",
        "#     plt.figure(figsize=(10, 5))\n",
        "#     for i, dist_file in enumerate(dist_files):\n",
        "#         dist_image = cv2.imread(os.path.join(output_path, dist_file), cv2.IMREAD_GRAYSCALE)\n",
        "#         plt.subplot(1, 4, i + 1)\n",
        "#         plt.imshow(dist_image, cmap='jet')\n",
        "#         plt.title(dist_file)\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "# else:\n",
        "#     print(\"_\")\n"
      ],
      "metadata": {
        "id": "Qb_gXy-b0_vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gabor (텍스처. 일단 중단)"
      ],
      "metadata": {
        "id": "W8xnF250P8PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def apply_gabor_filter(image):\n",
        "#     filters = []\n",
        "#     ksize = 31\n",
        "#     for theta in np.arange(0, np.pi, np.pi / 8):\n",
        "#         for sigma in [1, 3, 5]:\n",
        "#             kern = cv2.getGaborKernel((ksize, ksize), sigma, theta, 10, 0.5, 0, ktype=cv2.CV_32F)\n",
        "#             filters.append(kern)\n",
        "\n",
        "#     filtered_images = [cv2.filter2D(image, cv2.CV_8UC3, kern) for kern in filters]\n",
        "#     return filtered_images\n",
        "\n",
        "# dataset_path = \"/content/bread/\"\n",
        "\n",
        "# for bread in os.listdir(dataset_path):\n",
        "#     bread_path = os.path.join(dataset_path, bread, \"images\")\n",
        "\n",
        "#     if os.path.exists(bread_path):\n",
        "#         print(f\"{bread}🥖\")\n",
        "\n",
        "#         output_path = os.path.join(dataset_path, bread, \"gabor_images\")\n",
        "#         os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "#         for image_file in os.listdir(bread_path):\n",
        "#             if image_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "#                 image_path = os.path.join(bread_path, image_file)\n",
        "#                 image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "#                 if image is None:\n",
        "#                     continue\n",
        "\n",
        "#                 # gabor_images = apply_gabor_filter(image\n",
        "\n",
        "#                 for i, gabor_image in enumerate(gabor_images[:8]):\n",
        "#                     output_file = os.path.join(output_path, f\"{os.path.splitext(image_file)[0]}_gabor_{i}.jpg\")\n",
        "#                     cv2.imwrite(output_file, gabor_image)\n",
        "\n",
        "#         print(f\"{bread}: 저장 완료 {output_path}\")\n",
        "#     else:\n",
        "#         print(f\"{bread}: 이미지 없음\")"
      ],
      "metadata": {
        "id": "zeNgWsM6QARp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gabor 일부 시각화"
      ],
      "metadata": {
        "id": "ynxDL4EhQH32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for bread in os.listdir(dataset_path):\n",
        "#     output_path = os.path.join(dataset_path, bread, \"gabor_images\")\n",
        "#     if os.path.exists(output_path):\n",
        "#         gabor_files = sorted(os.listdir(output_path))[:8]\n",
        "#         print(f\"{bread}🥖\")\n",
        "#         plt.figure(figsize=(12, 8))\n",
        "#         for i, gabor_file in enumerate(gabor_files):\n",
        "#             gabor_image = cv2.imread(os.path.join(output_path, gabor_file), cv2.IMREAD_GRAYSCALE)\n",
        "#             plt.subplot(2, 4, i + 1)\n",
        "#             plt.imshow(gabor_image, cmap='gray')\n",
        "#             plt.title(gabor_file)\n",
        "#         plt.tight_layout()\n",
        "#         plt.show()\n"
      ],
      "metadata": {
        "id": "AmQ3iAk2QQix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 변경한 이미지 학습 데이터에 포함하기 (임시 중단)"
      ],
      "metadata": {
        "id": "7SSldxgCaH3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # 원본 이미지와 라벨 경로\n",
        "# images_path = \"/content/bread/train/images\"\n",
        "# labels_path = \"/content/bread/train/labels\"\n",
        "\n",
        "# # 이미지 파일 처리\n",
        "# for image_file in os.listdir(images_path):\n",
        "#     if \"_edges\" in image_file or \"_contours\" in image_file:  # edges와 contours 이미지만 처리\n",
        "#         # 원본 이미지 이름 추출\n",
        "#         original_name = image_file.replace(\"_edges\", \"\").replace(\"_contours\", \"\")\n",
        "#         original_label = os.path.join(labels_path, f\"{os.path.splitext(original_name)[0]}.txt\")\n",
        "\n",
        "#         # 새 라벨 이름 설정\n",
        "#         new_label = os.path.join(labels_path, f\"{os.path.splitext(image_file)[0]}.txt\")\n",
        "\n",
        "#         # 라벨 복사\n",
        "#         if os.path.exists(original_label):\n",
        "#             shutil.copy(original_label, new_label)\n",
        "#             print(f\"라벨 복사 완료: {original_label} → {new_label}\")\n",
        "#         else:\n",
        "#             print(f\"라벨 없음: {original_label}\")"
      ],
      "metadata": {
        "id": "AL7nFyxDaPmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train"
      ],
      "metadata": {
        "id": "8RgFvg9jWjrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "import torch\n",
        "from ultralytics import YOLO\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCAjSJ8nnvZ_",
        "outputId": "4789d0d2-a118-41a4-e8b4-4ba48b569d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.74-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.74-py3-none-any.whl (914 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.7/914.7 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.74 ultralytics-thop-2.0.14\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 모델 초기화\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# 학습 시작\n",
        "model.train(data='/content/bread/data.yaml', epochs=50, imgsz=640, patience=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW3FTcPu71Z2",
        "outputId": "b986eb1e-cb73-4d46-b695-6947de4be3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 140MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.74 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/bread/data.yaml, epochs=50, time=None, patience=3, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 84.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,012,408 parameters, 3,012,392 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 213MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xCumhxWwP4eg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9kAiCXlX9rhB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}