{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### import"
      ],
      "metadata": {
        "id": "c2eH8OLVhSq0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAUkG8sIjPIs"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "import zipfile\n",
        "import gdown\n",
        "import albumentations as A\n",
        "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ë§ˆìš´íŠ¸ ì‹œë„ (ì‹¤íŒ¨)\n",
        "\n",
        "\n",
        "> memo Gdownìœ¼ë¡œ í–ˆë”ë‹ˆ ì—ëŸ¬ê°€ ë‚˜ëŠ” ê±° ê°™ê³ , ë§ˆìš´íŠ¸ë¥¼ í•˜ë©´ ë‚´ ë“œë¼ì´ë¸Œì—ì„œ í•˜ë¼ê³  í•˜ê³ , ê³µìœ ì—ì„œëŠ” ì•ˆ ëœë‹¤ê³  í•˜ê³ .. ë¬´ìŠ¨ API ì„œë¹„ìŠ¤ ì‚¬ìš©í•˜ë¼ê³  í•˜ëŠ”ë° ê·¸ê±°ëŠ” í•˜ê¸°ê¹Œì§€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ê±° ê°™ê³ ...\n",
        "\n"
      ],
      "metadata": {
        "id": "dqGp3a6zmAES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drive.mount('/content/drive')\n",
        "\n",
        "# drive_folder = \"/content/drive/MyDrive/original_image/original_image\"\n",
        "# zip_filename = \"bread.zip\"\n",
        "\n",
        "# os.chdir(\"/content\")\n",
        "\n",
        "# with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "#     for root, dirs, files in os.walk(drive_folder):\n",
        "#         for file in files:\n",
        "#             file_path = os.path.join(root, file)\n",
        "#             zipf.write(file_path, os.path.relpath(file_path, drive_folder))\n",
        "\n",
        "# files.download(zip_filename)\n",
        "\n",
        "# print(f\"ë°ì´í„°ì…‹ ë‹¤ìš´ / ì••í•´ ì™„ë£Œ\")\n",
        "\n",
        "# # https://drive.google.com/drive/folders/1TEHUAt9HuD3rH5iqrdJQAB70cmOXcn_9?usp=sharing"
      ],
      "metadata": {
        "id": "JO1uocPGjWO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ì •ì„ë‹˜ì´ ì˜¬ë ¤ë‘ì‹  labeling data + image set (ìƒˆë¡œìš´ ë¼ë²¨ë§ ìœ„í•´ì„œ ì£¼ì„ ì²˜ë¦¬)"
      ],
      "metadata": {
        "id": "WLNiHJns6FRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # ì •ì„ë‹˜ì´ ì˜¬ë ¤ë‘ì‹  roboflow labeling data ê°€ì ¸ì˜¤ê¸°\n",
        "\n",
        "# # dataset_path = \"/content/bread/original_image\" # ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "\n",
        "# label_zip_file_id = \"10VZf9IqZ0bVHFCIcELrWmLS01Kh0pzF-\"\n",
        "# labeling_output_name = \"image_label_data.zip\"\n",
        "# # https://drive.google.com/file/d/10VZf9IqZ0bVHFCIcELrWmLS01Kh0pzF-/view?usp=drive_link\n",
        "\n",
        "# # ê¸°ì¡´ íŒŒì¼ ìˆìœ¼ë©´ ì‚­ì œ\n",
        "# if os.path.exists(labeling_output_name):\n",
        "#     os.remove(labeling_output_name)\n",
        "#     print(f\"ê¸°ì¡´ íŒŒì¼ ì‚­ì œ\")\n",
        "\n",
        "# gdown.download(f\"https://drive.google.com/uc?id={label_zip_file_id}\", labeling_output_name, quiet=False)\n",
        "# print(f\"labeling zip ë‹¤ìš´\")\n",
        "\n",
        "# # ì••ì¶•í•´ì œ ì ˆëŒ€ê²½ë¡œ ì„¤ì • í–ˆì§€ë§Œ ì•ˆë˜ëŠ” ê±° ê°™ì•„ì„œ ê·¸ëƒ¥ ë‘ê¸°ë¡œ\n",
        "# labels_path = \"/content/bread/\"\n",
        "\n",
        "# # ê¸°ì¡´ í´ë” ìˆìœ¼ë©´ ì‚­ì œ\n",
        "# if os.path.exists(labels_path):\n",
        "#     shutil.rmtree(labels_path)\n",
        "#     print(f\"ê¸°ì¡´ í´ë” ì‚­ì œ\")\n",
        "\n",
        "# os.makedirs(labels_path, exist_ok=True)\n",
        "\n",
        "# # ì••í•´\n",
        "# label_zip_file_path = os.path.join(os.getcwd(), labeling_output_name)\n",
        "\n",
        "# with zipfile.ZipFile(label_zip_file_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(labels_path)\n",
        "\n",
        "# print(f\"ì••ì¶• í•´ì œ ë°ì´í„° ê²½ë¡œ: {labels_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOZGeDafsuBx",
        "outputId": "47ec9e97-28aa-41a8-af93-966f5948cfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=10VZf9IqZ0bVHFCIcELrWmLS01Kh0pzF-\n",
            "From (redirected): https://drive.google.com/uc?id=10VZf9IqZ0bVHFCIcELrWmLS01Kh0pzF-&confirm=t&uuid=1ba515fe-b0fa-4b66-83d4-e6eeb56a8f90\n",
            "To: /content/image_label_data.zip\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53.4M/53.4M [00:02<00:00, 23.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeling zip ë‹¤ìš´\n",
            "ì••ì¶• í•´ì œ ë°ì´í„° ê²½ë¡œ: /content/bread/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âš ï¸ìœ¤ê³½ì„  í¬í•¨ ì‚¬ì§„ìœ¼ë¡œ ë¼ë²¨ë§ -> í›ˆë ¨ ê³¼ì • ìƒˆë¡œ ì‹œì‘\n",
        "\n",
        "\n",
        "> ì •ì„ë‹˜ì´ ì˜¬ë ¤ì£¼ì‹  labeling ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ë ¤ê³  í–ˆìœ¼ë‚˜, ì¦ê°• ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ê±¸ë¡œ ë‹¤ì‹œ ë¼ë²¨ë§ì´ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ì•Œê²Œ ëìŒ. edge/contours_detection ì ìš©í•œ ì‚¬ì§„ íŒŒì¼ì„ ì €ì¥í•˜ê³ , ë¹µ í´ë”ë³„ë¡œ êµ¬ë¶„í•´ì„œ í¬í•¨ì‹œì¼œë†“ì€ ë‹¤ìŒì—, ë‹¤ì‹œ ë¼ë²¨ë§í•˜ê³ , gdowní•˜ê³ , í›ˆë ¨ ëŒë¦¬ë©´ ëœë‹¤.\n",
        "\n"
      ],
      "metadata": {
        "id": "2OoZwERc1DHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gdown(ì´ì „ ë²„ì „)(ì£¼ì„ì²˜ë¦¬)"
      ],
      "metadata": {
        "id": "o0oCpxyri5s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# zip_file_id = \"1kSApTuj4bC3vtHJ-0t2HTkPaay7CTt0H\"\n",
        "# output_name = \"bread_data.zip\"\n",
        "\n",
        "# # ê¸°ì¡´ íŒŒì¼ ìˆìœ¼ë©´ ì‚­ì œ\n",
        "# if os.path.exists(output_name):\n",
        "#     os.remove(output_name)\n",
        "#     print(f\"ê¸°ì¡´ íŒŒì¼ ì‚­ì œ\")\n",
        "\n",
        "# gdown.download(f\"https://drive.google.com/uc?id={zip_file_id}\", output_name, quiet=False)\n",
        "# print(f\"zip ë‹¤ìš´\")\n",
        "\n",
        "# # ì••ì¶•í•´ì œ ì ˆëŒ€ê²½ë¡œ ì„¤ì • í–ˆì§€ë§Œ ì•ˆë˜ëŠ” ê±° ê°™ì•„ì„œ ê·¸ëƒ¥ ë‘ê¸°ë¡œ\n",
        "# extract_path = r\"bread\"\n",
        "\n",
        "# # ê¸°ì¡´ í´ë” ìˆìœ¼ë©´ ì‚­ì œ\n",
        "# if os.path.exists(extract_path):\n",
        "#     shutil.rmtree(extract_path)\n",
        "#     print(f\"ê¸°ì¡´ í´ë” ì‚­ì œ\")\n",
        "\n",
        "# os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# # ì••í•´\n",
        "# zip_file_path = os.path.join(os.getcwd(), output_name)\n",
        "\n",
        "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_path)\n",
        "\n",
        "# print(f\"ì••ì¶• í•´ì œ ë°ì´í„° ê²½ë¡œ: {extract_path}\")"
      ],
      "metadata": {
        "id": "0qko9xOk1G5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ìœ¤ê³½ì„ /ê²½ê³„ì„  : Edge ë° Contour Detection í•¨ìˆ˜"
      ],
      "metadata": {
        "id": "v96WyWqhQcB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def detect_edges_and_contours(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ì–´ìš”: {image_path}\")\n",
        "        return None, None\n",
        "\n",
        "    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ (ê²½ê³„ì„  ê°•í™”!)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Canny Edge Detection\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "    # Contour Detection\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contour_image = image.copy()\n",
        "    cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
        "\n",
        "    return edges, contour_image\n",
        "\n",
        "dataset_path = \"/content/bread/train/images/\"\n",
        "output_path = \"/content/bread/edge/\"\n",
        "\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "for image_file in os.listdir(dataset_path):\n",
        "    if image_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "        image_path = os.path.join(dataset_path, image_file)\n",
        "\n",
        "        # ê²½ê³„ì„  ë° ìœ¤ê³½ì„  ì¶”ì¶œ\n",
        "        edges, contour_image = detect_edges_and_contours(image_path)\n",
        "        if edges is not None:\n",
        "\n",
        "            edge_output = os.path.join(output_path, f\"{os.path.splitext(image_file)[0]}_edges.jpg\")\n",
        "            contour_output = os.path.join(output_path, f\"{os.path.splitext(image_file)[0]}_contours.jpg\")\n",
        "\n",
        "            cv2.imwrite(edge_output, edges)  # ê²½ê³„ì„  ì´ë¯¸ì§€ ì €ì¥\n",
        "            cv2.imwrite(contour_output, contour_image)  # ìœ¤ê³½ì„  ì´ë¯¸ì§€ ì €ì¥\n",
        "\n",
        "print(f\"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NLPgM71yQbpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd17d29-fbca-41a8-e53c-5223c8780913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ê²°ê³¼ ì €ì¥ ì™„ë£Œ: /content/bread/edge/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shutil.make_archive(\"/content/bread/edge\", 'zip', \"/content/bread/edge\")\n",
        "\n",
        "# files.download(\"/content/bread/edge.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MMLALxhBoDAd",
        "outputId": "06e369ed-b6f7-49db-b4c2-a1bfcb59d006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2dbeb931-8617-4f9d-836d-82d7b3c7b404\", \"edge.zip\", 156427199)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ë² ì´ê¸€ë¡œ í…ŒìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "Ip0yG93qQkqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bread = \"bagel\" # ìƒ˜í”Œ\n",
        "# output_path = os.path.join(dataset_path, bread, \"edge_contours\")\n",
        "# if os.path.exists(output_path):\n",
        "#     edge_files = sorted([f for f in os.listdir(output_path) if \"edges\" in f])[:4]\n",
        "\n",
        "#     plt.figure(figsize=(10, 5))\n",
        "#     for i, edge_file in enumerate(edge_files):\n",
        "#         edge_image = cv2.imread(os.path.join(output_path, edge_file), cv2.IMREAD_GRAYSCALE)\n",
        "#         plt.subplot(1, 4, i + 1)\n",
        "#         plt.imshow(edge_image, cmap='gray')\n",
        "#         plt.title(edge_file)\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "# else:\n",
        "#     print(\"_\")"
      ],
      "metadata": {
        "id": "kDvYtX7tQjtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distance Transform í™œìš© (ì„ì‹œ ì¤‘ë‹¨)"
      ],
      "metadata": {
        "id": "b95kH8J2zd_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def apply_distance_transform(image_path):\n",
        "#     image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "#     if image is None:\n",
        "#         return None\n",
        "\n",
        "#     _, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "#     dist_transform = cv2.distanceTransform(binary, cv2.DIST_L2, 3)\n",
        "#     return dist_transform\n",
        "\n",
        "# dataset_path = \"/content/bread/original_image\"\n",
        "\n",
        "# for bread in os.listdir(dataset_path):\n",
        "#     bread_images_path = os.path.join(dataset_path, bread, \"images\")\n",
        "#     if os.path.exists(bread_images_path):\n",
        "#         print(f\"{bread}...\")\n",
        "\n",
        "#         output_path = os.path.join(dataset_path, bread, \"distance_transform\")\n",
        "#         os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "#         for image_file in os.listdir(bread_images_path):\n",
        "#             if image_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "#                 image_path = os.path.join(bread_images_path, image_file)\n",
        "\n",
        "#                 distance_image = apply_distance_transform(image_path)\n",
        "#                 if distance_image is not None:\n",
        "#                     output_file = os.path.join(output_path, f\"{os.path.splitext(image_file)[0]}_dist.jpg\")\n",
        "#                     cv2.imwrite(output_file, (distance_image * 255).astype(\"uint8\"))  # 0~255ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •\n",
        "\n",
        "#         print(f\"{bread}:{output_path} ì €ì¥\")\n",
        "#     else:\n",
        "#         print(f\"{bread}: ì´ë¯¸ì§€ ì—†ìŒ\")\n"
      ],
      "metadata": {
        "id": "kmC_w-9kzfn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bread = \"bagel\"\n",
        "# output_path = os.path.join(dataset_path, bread, \"distance_transform\")\n",
        "\n",
        "# if os.path.exists(output_path):\n",
        "#     dist_files = sorted(os.listdir(output_path))[:4]\n",
        "\n",
        "#     plt.figure(figsize=(10, 5))\n",
        "#     for i, dist_file in enumerate(dist_files):\n",
        "#         dist_image = cv2.imread(os.path.join(output_path, dist_file), cv2.IMREAD_GRAYSCALE)\n",
        "#         plt.subplot(1, 4, i + 1)\n",
        "#         plt.imshow(dist_image, cmap='jet')\n",
        "#         plt.title(dist_file)\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "# else:\n",
        "#     print(\"_\")\n"
      ],
      "metadata": {
        "id": "Qb_gXy-b0_vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gabor (í…ìŠ¤ì²˜. ì¼ë‹¨ ì¤‘ë‹¨)"
      ],
      "metadata": {
        "id": "W8xnF250P8PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def apply_gabor_filter(image):\n",
        "#     filters = []\n",
        "#     ksize = 31\n",
        "#     for theta in np.arange(0, np.pi, np.pi / 8):\n",
        "#         for sigma in [1, 3, 5]:\n",
        "#             kern = cv2.getGaborKernel((ksize, ksize), sigma, theta, 10, 0.5, 0, ktype=cv2.CV_32F)\n",
        "#             filters.append(kern)\n",
        "\n",
        "#     filtered_images = [cv2.filter2D(image, cv2.CV_8UC3, kern) for kern in filters]\n",
        "#     return filtered_images\n",
        "\n",
        "# dataset_path = \"/content/bread/\"\n",
        "\n",
        "# for bread in os.listdir(dataset_path):\n",
        "#     bread_path = os.path.join(dataset_path, bread, \"images\")\n",
        "\n",
        "#     if os.path.exists(bread_path):\n",
        "#         print(f\"{bread}ğŸ¥–\")\n",
        "\n",
        "#         output_path = os.path.join(dataset_path, bread, \"gabor_images\")\n",
        "#         os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "#         for image_file in os.listdir(bread_path):\n",
        "#             if image_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "#                 image_path = os.path.join(bread_path, image_file)\n",
        "#                 image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "#                 if image is None:\n",
        "#                     continue\n",
        "\n",
        "#                 # gabor_images = apply_gabor_filter(image\n",
        "\n",
        "#                 for i, gabor_image in enumerate(gabor_images[:8]):\n",
        "#                     output_file = os.path.join(output_path, f\"{os.path.splitext(image_file)[0]}_gabor_{i}.jpg\")\n",
        "#                     cv2.imwrite(output_file, gabor_image)\n",
        "\n",
        "#         print(f\"{bread}: ì €ì¥ ì™„ë£Œ {output_path}\")\n",
        "#     else:\n",
        "#         print(f\"{bread}: ì´ë¯¸ì§€ ì—†ìŒ\")"
      ],
      "metadata": {
        "id": "zeNgWsM6QARp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gabor ì¼ë¶€ ì‹œê°í™”"
      ],
      "metadata": {
        "id": "ynxDL4EhQH32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for bread in os.listdir(dataset_path):\n",
        "#     output_path = os.path.join(dataset_path, bread, \"gabor_images\")\n",
        "#     if os.path.exists(output_path):\n",
        "#         gabor_files = sorted(os.listdir(output_path))[:8]\n",
        "#         print(f\"{bread}ğŸ¥–\")\n",
        "#         plt.figure(figsize=(12, 8))\n",
        "#         for i, gabor_file in enumerate(gabor_files):\n",
        "#             gabor_image = cv2.imread(os.path.join(output_path, gabor_file), cv2.IMREAD_GRAYSCALE)\n",
        "#             plt.subplot(2, 4, i + 1)\n",
        "#             plt.imshow(gabor_image, cmap='gray')\n",
        "#             plt.title(gabor_file)\n",
        "#         plt.tight_layout()\n",
        "#         plt.show()\n"
      ],
      "metadata": {
        "id": "AmQ3iAk2QQix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ë³€ê²½í•œ ì´ë¯¸ì§€ í•™ìŠµ ë°ì´í„°ì— í¬í•¨í•˜ê¸° (ì„ì‹œ ì¤‘ë‹¨)"
      ],
      "metadata": {
        "id": "7SSldxgCaH3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # ì›ë³¸ ì´ë¯¸ì§€ì™€ ë¼ë²¨ ê²½ë¡œ\n",
        "# images_path = \"/content/bread/train/images\"\n",
        "# labels_path = \"/content/bread/train/labels\"\n",
        "\n",
        "# # ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬\n",
        "# for image_file in os.listdir(images_path):\n",
        "#     if \"_edges\" in image_file or \"_contours\" in image_file:  # edgesì™€ contours ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬\n",
        "#         # ì›ë³¸ ì´ë¯¸ì§€ ì´ë¦„ ì¶”ì¶œ\n",
        "#         original_name = image_file.replace(\"_edges\", \"\").replace(\"_contours\", \"\")\n",
        "#         original_label = os.path.join(labels_path, f\"{os.path.splitext(original_name)[0]}.txt\")\n",
        "\n",
        "#         # ìƒˆ ë¼ë²¨ ì´ë¦„ ì„¤ì •\n",
        "#         new_label = os.path.join(labels_path, f\"{os.path.splitext(image_file)[0]}.txt\")\n",
        "\n",
        "#         # ë¼ë²¨ ë³µì‚¬\n",
        "#         if os.path.exists(original_label):\n",
        "#             shutil.copy(original_label, new_label)\n",
        "#             print(f\"ë¼ë²¨ ë³µì‚¬ ì™„ë£Œ: {original_label} â†’ {new_label}\")\n",
        "#         else:\n",
        "#             print(f\"ë¼ë²¨ ì—†ìŒ: {original_label}\")"
      ],
      "metadata": {
        "id": "AL7nFyxDaPmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train"
      ],
      "metadata": {
        "id": "8RgFvg9jWjrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "import torch\n",
        "from ultralytics import YOLO\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCAjSJ8nnvZ_",
        "outputId": "4789d0d2-a118-41a4-e8b4-4ba48b569d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.74-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.74-py3-none-any.whl (914 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m914.7/914.7 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.74 ultralytics-thop-2.0.14\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 ëª¨ë¸ ì´ˆê¸°í™”\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# í•™ìŠµ ì‹œì‘\n",
        "model.train(data='/content/bread/data.yaml', epochs=50, imgsz=640, patience=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW3FTcPu71Z2",
        "outputId": "b986eb1e-cb73-4d46-b695-6947de4be3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 140MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.74 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/bread/data.yaml, epochs=50, time=None, patience=3, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 84.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,012,408 parameters, 3,012,392 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 213MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xCumhxWwP4eg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9kAiCXlX9rhB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}